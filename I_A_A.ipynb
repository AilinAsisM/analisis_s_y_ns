{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivos:** \n",
    "- Implementar los modelos vistos en clase tanŧo de regresión como de claificación sobre el data set de galaxias \n",
    "- Realizar un análisis de los resultados obtenidos que cada una de las pruebas\n",
    "- Comparar la performance y seleccionar el mejor modelo tanto para tabla como para imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paquetes necesarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('galaxias_2.csv', index_col=['objID'])\n",
    "display(dataset.head(2))\n",
    "display(dataset.shape)\n",
    "display('distribución de las variables físicas de las galaxias')\n",
    "dataset.hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl = dataset.loc[~(dataset.index.astype(str).duplicated(keep=\"first\"))]\n",
    "data_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_type(row):\n",
    "    if row[\"elliptical\"]:\n",
    "        return \"E\"\n",
    "    elif row[\"spiral\"]:\n",
    "        return \"S\"\n",
    "    else:\n",
    "        return \"I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl[\"Type\"] = data_cl.apply(galaxy_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data_cl[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_cl.isna(), yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_per_type(df, col_name=\"\", bins=20):\n",
    "    plt.title(f\"{col_name.capitalize()} Distribution\")\n",
    "    sns.distplot(df[df[\"elliptical\"] == 1][col_name],label=\"elliptical\", bins=bins)\n",
    "    sns.distplot(df[df[\"spiral\"] == 1][col_name],label=\"spiral\", bins=bins)\n",
    "    sns.distplot(df[df[\"uncertain\"] == 1][col_name],label=\"irregular\", bins=bins)\n",
    "    plt.legend()\n",
    "    \n",
    "def exploratory_plots(df, col_name=\"\"):\n",
    "    plt.subplot(3, 1, 1)\n",
    "    distribution_per_type(df, col_name)\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title(f\"{col_name.capitalize()} Boxplot\")\n",
    "    sns.boxplot(x=\"Type\", y=col_name, data=df)\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title(f\"{col_name.capitalize()} Boxplot w/o Outliers\")\n",
    "    sns.boxplot(x=\"Type\", y=col_name, data=df, showfliers=False)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols = ['petroR90_r', 'Color', 'distancia_L', 'Mag_abs', 'Type']\n",
    "sns.pairplot(data_cl[plot_cols], hue=\"Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_plots(data_cl, \"Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PetroR90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_plots(data_cl, \"petroR90_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_plots(data_cl, \"distancia_L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mag_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_plots(data_cl, \"Mag_abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mag in ['modelMag_u', 'modelMag_g', 'modelMag_r', 'modelMag_i','modelMag_z']:\n",
    "    plt.figure()\n",
    "    exploratory_plots(data_cl, mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una relación empírica entre el radio efectivo (petro petroR90_r) y la magnitud absoluta para galaxias  (datos de Bender et al. 1992, ApJ., 399, 462)\n",
    "\n",
    "Por lo tanto, el valor a predecir sera  **Mag_abs** la cual está contenida en un intervalo real de tamaño ~ 9mag, el atributo a usar sera el logaritmo en base diez de la variable **petroR90_r**.\n",
    "\n",
    "Detallar los pasos realizados (split, fit, metrica..) en el uso de el algoritmo de Regresión lineal con y sin regularización.\n",
    "\n",
    "Responda:\n",
    "- Que significa el error cuadrático?\n",
    "- Que unidades tiene?\n",
    "- Es necesaria la regularización?\n",
    "- Es bueno valor obtenido en la métrica?\n",
    "- Que pasa si se distingue por tipo de galaxia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl[\"log_petroR90\"] = np.log10(data_cl[\"petroR90_r\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2)\n",
    "sns.distplot(data_cl[\"log_petroR90\"], ax=axs[0])\n",
    "sns.scatterplot(x=\"log_petroR90\", y=\"Mag_abs\", data=data_cl,hue=\"Type\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_cl[\"log_petroR90\"]\n",
    "y = data_cl[\"Mag_abs\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42421)\n",
    "X_train, X_test = X_train.values.reshape(-1,1), X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Lineal y Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model_lasso = Lasso(alpha=0.01, random_state=4212)\n",
    "model_lasso.fit(X_train, y_train)\n",
    "#list(zip(X.columns, model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_lasso = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*80)\n",
    "print(\"Linear Regression\")\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"SE:  \", mean_squared_error(y_test, y_pred) * y_test.shape[0])\n",
    "print(\"-\"*80)\n",
    "print(\"Linear Regression with Lasso Regularization\")\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred_lasso))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred_lasso))\n",
    "print(\"SE:  \", mean_squared_error(y_test, y_pred_lasso) * y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_test.reshape(1,-1)[0], y=y_test, label=\"Test Target\")\n",
    "sns.scatterplot(x=X_test.reshape(1,-1)[0], y=y_pred, label=\"Predicted Target\")\n",
    "plt.xlabel(\"log_petroR90\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_pred, y=y_test)\n",
    "plt.xlabel(\"Predicted Target\")\n",
    "plt.ylabel(\"Test Target\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo por tipo de galaxia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d, y_d = {}, {}\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = {}, {}, {}, {}\n",
    "\n",
    "for ttype in data_cl[\"Type\"].unique():\n",
    "    mask = data_cl[\"Type\"] == ttype\n",
    "    X_d[ttype] = data_cl[mask][\"log_petroR90\"]\n",
    "    y_d[ttype] = data_cl[mask][\"Mag_abs\"]\n",
    "\n",
    "    X_train_d[ttype], X_test_d[ttype], y_train_d[ttype], y_test_d[ttype] = \\\n",
    "    train_test_split(X_d[ttype], y_d[ttype], test_size=0.2, random_state=42421)\n",
    "    X_train_d[ttype], X_test_d[ttype] = X_train_d[ttype].values.reshape(-1,1), X_test_d[ttype].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "y_pred_train_d = {}\n",
    "y_pred_test_d  = {}\n",
    "for ttype in data_cl[\"Type\"].unique():\n",
    "    models[ttype] = LinearRegression()\n",
    "    models[ttype].fit(X_train_d[ttype], y_train_d[ttype])\n",
    "    y_pred_train_d[ttype] = models[ttype].predict(X_train_d[ttype])\n",
    "    y_pred_test_d[ttype] = models[ttype].predict(X_test_d[ttype])\n",
    "\n",
    "for ttype in data_cl[\"Type\"].unique():\n",
    "    print(\"-\"*80)\n",
    "    print(ttype)\n",
    "    print(\"-\"*80)\n",
    "    print(\"R2 Score: \", r2_score(y_test_d[ttype], y_pred_test_d[ttype]))\n",
    "    print(\"MSE: \", mean_squared_error(y_test_d[ttype], y_pred_test_d[ttype]))\n",
    "    print(models[ttype].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ttype in data_cl[\"Type\"].unique()[::-1]:\n",
    "    sns.scatterplot(x=y_pred_test_d[ttype], y=y_test_d[ttype], alpha=0.8, label=ttype)\n",
    "    plt.grid()\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(3,1, figsize=(10,10))\n",
    "for idx, ttype in enumerate(data_cl[\"Type\"].unique()):\n",
    "    sns.scatterplot(y=y_test_d[ttype],      x=X_test_d[ttype].reshape(1,-1)[0], ax=axs[idx],\n",
    "                   label=\"Predicted Target\")\n",
    "    sns.scatterplot(y=y_pred_test_d[ttype], x=X_test_d[ttype].reshape(1,-1)[0], ax=axs[idx], \n",
    "                    label=\"Test Target\")\n",
    "    \n",
    "    axs[idx].set_xlabel(\"log_petroR90\")\n",
    "    axs[idx].set_ylabel(\"Mag_Abs\")\n",
    "    axs[idx].legend()\n",
    "    axs[idx].grid()\n",
    "    axs[idx].set_title(ttype)\n",
    "    axs[idx].set_ylim([-23, -16])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(3,1, figsize=(10,10))\n",
    "for idx, ttype in enumerate(data_cl[\"Type\"].unique()):\n",
    "    sns.scatterplot(x=y_pred_test_d[ttype], y=y_test_d[ttype], ax=axs[idx])\n",
    "    axs[idx].grid()\n",
    "    axs[idx].set_title(ttype)\n",
    "    axs[idx].set_xlabel(\"Predicted Target\")\n",
    "    axs[idx].set_ylabel(\"Test Target\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación binaria \n",
    "\n",
    "Haga uso de los atributos petroR90_r, Color y Mag_abs para clasificar en  elípticas y espirales.\n",
    "\n",
    "Use los siguientes modelos:\n",
    "\n",
    "    - Perceptrón\n",
    "    - Regresión logística\n",
    "    - Vecinos más cercanos\n",
    "    \n",
    "Para cada uno de ellos muestre:\n",
    "\n",
    "        - Matriz de confusión\n",
    "        - Visualización de la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = data_cl[data_cl[\"Type\"] != \"I\"]\n",
    "sns.countplot(data_clf[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clf = data_clf[[\"petroR90_r\", \"Mag_abs\", \"Color\"]]\n",
    "y_clf = data_clf[\"Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42421)\n",
    "#X_train, X_test = X_train.values.reshape(-1,1), X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "X_test_std   = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(y_real, y_pred):\n",
    "    print(f\"Accuracy {accuracy_score(y_real, y_pred)}\")\n",
    "    print(\"-\"*100)\n",
    "    print(classification_report(y_real, y_pred))\n",
    "    plt.figure()\n",
    "    sns.heatmap(confusion_matrix(y_real, y_pred), \n",
    "                #xticklabels=x_ticks, #[0, 1],\n",
    "                #yticklabels=x_ticks, #[0, 1],\n",
    "                cmap=\"jet\",\n",
    "                annot=True,\n",
    "               )\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.ylabel(\"Real Class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc    = Perceptron(random_state=421)\n",
    "log_reg = LogisticRegression(random_state=421)\n",
    "knn     = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiper parametros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [perc, log_reg, knn]:\n",
    "    model.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in [perc, log_reg, knn]:\n",
    "    y_pred_train = model.predict(X_train_std)\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    print(\"=\"*80)\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Accuracy Train: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"F1 score Train: \", f1_score(y_train, y_pred_train, pos_label = 'S'))\n",
    "    print(\"Accuracy Test: \", accuracy_score(y_test, y_pred_test))\n",
    "    print(\"F1 score Test: \", f1_score(y_test, y_pred_test, pos_label = 'S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [log_reg, knn]:\n",
    "    y_pred_train = model.predict(X_train_std)\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    print(\"=\"*80)\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Train\")\n",
    "    print(\"-\"*80)\n",
    "    print_classification_report(y_train, y_pred_train)\n",
    "    print(\"-\"*80)\n",
    "    print(\"Test\")\n",
    "    print(\"-\"*80)\n",
    "    print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste Hiper Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no hay muchos hiperparametros vamos a usar validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_logspace =  np.logspace(-6,1,7)\n",
    "train_scores, valid_scores =  validation_curve(LogisticRegression(solver=\"lbfgs\"),\n",
    "                                               X_train_std, y_train, \"C\", x_logspace,\n",
    "                                               cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(x_logspace, np.mean(train_scores,axis=1), \"-ob\", label=\"Train\")\n",
    "plt.semilogx(x_logspace, np.mean(valid_scores,axis=1), \"-xr\", label=\"Validation\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Regularization Coeficient\")\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_logspace =  range(1, 15)\n",
    "train_scores, valid_scores =  validation_curve(KNeighborsClassifier(),\n",
    "                                               X_train_std, y_train, \"n_neighbors\", x_logspace,\n",
    "                                               cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_logspace, np.mean(train_scores,axis=1), \"-ob\", label=\"Train\")\n",
    "plt.plot(x_logspace, np.mean(valid_scores,axis=1), \"-xr\", label=\"Validation\")\n",
    "plt.grid()\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que pasa con el test cuando usamos nneighbors = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred_train = knn.predict(X_train_std)\n",
    "y_pred_test = knn.predict(X_test_std)\n",
    "print(\"=\"*80)\n",
    "print(knn.__class__.__name__)\n",
    "print(\"=\"*80)\n",
    "print(\"Train\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_train, y_pred_train)\n",
    "print(\"-\"*80)\n",
    "print(\"Test\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas Precision/Recall y ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y_scores = cross_val_predict(LogisticRegression(solver=\"lbfgs\"),\n",
    "                                               X_train_std, y_train ,cv=5,\n",
    "                                               method=\"decision_function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, th = precision_recall_curve(LabelEncoder().fit_transform(y_train), y_scores)\n",
    "plt.plot(th, prec[:-1], \"--b\", label=\"Precision\")\n",
    "plt.plot(th, rec[:-1], \"--r\", label=\"Recall\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, th = roc_curve(LabelEncoder().fit_transform(y_train), y_scores)\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Log Regr\")\n",
    "plt.plot([0,1],[0,1], \"--k\")\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel(\"False Poisitive Rate\")\n",
    "plt.ylabel(\"True Poisitive Rate\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fronteras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from ml.visualization import plot_confusion_matrix, classifier_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación multiclase\n",
    "Haga uso de los atributos petroR90_r, Color y Mag_abs para clasificar en elípticas, espirales e irregulares.\n",
    "\n",
    "Use los siguientes modelos:\n",
    "\n",
    "    - SGDClassifier con y sin Ajuste de Hiperparámetros\n",
    "    - Árbol de Decisión con y sin Ajuste de Hiperparámetros\n",
    "    \n",
    "Para cada uno de ellos muestre:\n",
    "\n",
    "        - Accuracy\n",
    "        - Precision\n",
    "        - Recall\n",
    "        - F1\n",
    "        - matriz de confusión\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda: \n",
    "- Que métrica es la más apropiadad a usar en este problema de clasificación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf = data_cl\n",
    "X_clf = data_clf[[\"petroR90_r\", \"Mag_abs\", \"Color\"]]\n",
    "y_clf = data_clf[\"Type\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42421)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "X_test_std   = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf    = SGDClassifier(random_state=421)\n",
    "tree_clf = DecisionTreeClassifier(random_state=421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [sgd_clf,tree_clf]:\n",
    "    model.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in [sgd_clf,tree_clf]:\n",
    "    y_pred_train = model.predict(X_train_std)\n",
    "    y_pred_test = model.predict(X_test_std)\n",
    "    print(\"=\"*80)\n",
    "    print(model.__class__.__name__)\n",
    "    print(\"=\"*80)\n",
    "    print(\"Accuracy Train: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"F1-score Train: \", f1_score(y_train, y_pred_train, average = 'weighted'))\n",
    "    print(\"Accuracy Test: \", accuracy_score(y_test, y_pred_test))\n",
    "    print(\"F1-score Test: \", f1_score(y_train, y_pred_train, average = 'weighted'))\n",
    "    #print(\"Train\")\n",
    "    #print(\"-\"*80)\n",
    "    #print_classification_report(y_train, y_pred_train)\n",
    "    #print(\"-\"*80)\n",
    "    #print(\"Test\")\n",
    "    #print(\"-\"*80)\n",
    "    #print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Hiper Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"loss\":['hinge', 'log', \"perceptron\"],\n",
    "    \"penalty\": [\"l1\", \"l2\", None],\n",
    "    \"alpha\": [1e-5, 1e-4, 1e-3],\n",
    "    }\n",
    "sgd_clf    = SGDClassifier(random_state=2402)\n",
    "grid_sgd = GridSearchCV(sgd_clf, param_grid=param_grid, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgd.fit(X_train_std, y_train)\n",
    "means = grid_sgd.cv_results_['mean_test_score']\n",
    "stds = grid_sgd.cv_results_['std_test_score']\n",
    "for mean, std, params in sorted(zip(means, stds, grid_sgd.cv_results_['params']), \n",
    "                                key=lambda data: data[0], reverse=True):\n",
    "    print(\"%0.4f (+/-%0.04f) para %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sgd = grid_sgd.best_estimator_\n",
    "best_sgd.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_train = best_sgd.predict(X_train_std)\n",
    "y_pred_test = best_sgd.predict(X_test_std)\n",
    "print(\"=\"*80)\n",
    "print(best_sgd.__class__.__name__)\n",
    "print(\"=\"*80)\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_train, y_pred_train)\n",
    "print(\"-\"*80)\n",
    "print(\"Test\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\":['gini', 'entropy'],\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6],\n",
    "    }\n",
    "tree_clf = DecisionTreeClassifier(random_state=421)\n",
    "grid_tree = GridSearchCV(tree_clf, param_grid=param_grid, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree.fit(X_train_std, y_train)\n",
    "means = grid_tree.cv_results_['mean_test_score']\n",
    "stds = grid_tree.cv_results_['std_test_score']\n",
    "for mean, std, params in sorted(zip(means, stds, grid_tree.cv_results_['params']), \n",
    "                                key=lambda data: data[0], reverse=True):\n",
    "    print(\"%0.4f (+/-%0.04f) para %r\" % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_tree.best_estimator_\n",
    "best_tree.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_train = best_tree.predict(X_train_std)\n",
    "y_pred_test = best_tree.predict(X_test_std)\n",
    "print(\"=\"*80)\n",
    "print(model.__class__.__name__)\n",
    "print(\"=\"*80)\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_train, y_pred_train)\n",
    "print(\"-\"*80)\n",
    "print(\"Test\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión tiene la forma<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X | Positives | Negatives |\n",
    "| --- | --- | --- |\n",
    "| **Positives** | True Positives  | False Positives |\n",
    "| **Negatives** | False Negatives | True Negatives  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una metrica que nos dice el accuracy que tenemos sobre los valores verdaderos es **precision**. Nos dice cuantos de los valores que detectamos como verdaderos realmente lo son:\n",
    "\n",
    "$precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "Otra metrica interesante es **recall**. Nos dice que tan bueno fue el algoritmo para detectar bien a los positivos.\n",
    "\n",
    "$recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "El **F1 score** es un promedio armonico de los 2 anteriores y solamnete va a tener un valor alto cuando los otros 2 sean altos\n",
    "\n",
    "$F1 = 2 \\times \\frac{precision \\times recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos F1 como score porque las clases se encuentran desbalanceadas en este caso y ademas no tenemos especial interes en ninguna clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score: f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\":['gini', 'entropy'],\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6],\n",
    "    }\n",
    "tree_clf = DecisionTreeClassifier(random_state=421)\n",
    "grid_tree = GridSearchCV(tree_clf, param_grid=param_grid, cv=5, scoring=\"f1_weighted\")\n",
    "grid_tree.fit(X_train_std, y_train)\n",
    "means = grid_tree.cv_results_['mean_test_score']\n",
    "stds = grid_tree.cv_results_['std_test_score']\n",
    "for mean, std, params in sorted(zip(means, stds, grid_tree.cv_results_['params']), \n",
    "                                key=lambda data: data[0], reverse=True):\n",
    "    print(\"%0.4f (+/-%0.04f) para %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_tree.best_estimator_\n",
    "best_tree.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred_train = best_tree.predict(X_train_std)\n",
    "y_pred_test = best_tree.predict(X_test_std)\n",
    "print(\"=\"*80)\n",
    "print(best_tree.__class__.__name__)\n",
    "print(\"=\"*80)\n",
    "print(\"Train: \", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test: \", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Train\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_train, y_pred_train)\n",
    "print(\"-\"*80)\n",
    "print(\"Test\")\n",
    "print(\"-\"*80)\n",
    "print_classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos ahora que sucede al balancear las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: to the selected model we must be able to apply the fit method. Either way we can't use this function.\n",
    "\n",
    "def cv_and_smote(clf, x_train, y_train, x_test, rnd = 22):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    x_train_df = pd.DataFrame(x_train) \n",
    "    y_train_df = pd.DataFrame(y_train)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, random_state=rnd)\n",
    "\n",
    "    # lists to append scores\n",
    "    cross_val_f1_score_lst = []\n",
    "    cross_val_accuracy_lst = []\n",
    "    cross_val_recall_lst = []\n",
    "    cross_val_precision_lst = []\n",
    "\n",
    "    for train_index_ls, validation_index_ls in kf.split(x_train, y_train):\n",
    "    \n",
    "        # splitting on train/validation    \n",
    "        train, validation = x_train_df.iloc[train_index_ls], x_train_df.iloc[validation_index_ls]\n",
    "        target_train, target_val = y_train_df.iloc[train_index_ls], y_train_df.iloc[validation_index_ls]\n",
    "    \n",
    "        sm = SMOTE(random_state=rnd)\n",
    "    \n",
    "        X_train_res, y_train_res = sm.fit_sample(train, target_train)\n",
    "    \n",
    "        # model definition\n",
    "        clf.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        # testing on 1 fold of validation set\n",
    "        validation_pred = clf.predict(validation)\n",
    "    \n",
    "        # appending scores of differnet metrics\n",
    "        cross_val_recall_lst.append(recall_score(target_val, validation_pred, average = 'macro'))\n",
    "        cross_val_accuracy_lst.append(accuracy_score(target_val, validation_pred))\n",
    "        cross_val_precision_lst.append(precision_score(target_val, validation_pred, average = 'macro'))\n",
    "        cross_val_f1_score_lst.append(f1_score(target_val, validation_pred, average = 'macro'))\n",
    "           \n",
    "    y_pred_test = clf.predict(x_test) \n",
    "    \n",
    "    return (np.mean(cross_val_accuracy_lst), \n",
    "            np.mean(cross_val_recall_lst), \n",
    "            np.mean(cross_val_precision_lst), \n",
    "            np.mean(cross_val_f1_score_lst), \n",
    "            y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, \n",
    "- Armen un conjunto de 100 imágenes [300, 300, 5] (guarden ese conjunto de datos. img.formato)\n",
    "- Elijan el modelo con la mejor performance y apliquen sobre el conjunto de imágenes. \n",
    "\n",
    "- Dejen un análisis de las performas que obtiene con ese modelo tanto para imágenes como para valores de tabla. \n",
    "- Está bn realizar este procedimiento en este tipo de problema?. Es decir, tomar un modelo que clasifica bien a el mismo conjunto de galaxias usando datos de tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
